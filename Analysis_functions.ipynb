{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b3c142",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88df0edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Visualization_functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.table import QTable\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/home/emelie/Desktop/Codes/PETAR/PeTar-master/tools/')\n",
    "from analysis import *\n",
    "\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from Visualization_functions import snapshots_plot, anim_disc, anim_3d, anim_ComparetoTraceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ef65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'xtick.labelsize':13, 'ytick.labelsize':13, 'axes.titlesize':16, \n",
    "                     'axes.grid':True, 'axes.labelsize':15, 'legend.fontsize':13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1904a9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b2c2e",
   "metadata": {},
   "source": [
    "### Extracting data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d197b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(name_run, name_folder, tmax, toutput):\n",
    "    \"\"\"\n",
    "    Extracts data from petar snapshot files and checks the data\n",
    "    ------------------------------------------------------------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    name_run: str\n",
    "        Name of the run. NOTE! Do not forget to add an r before the string!!!\n",
    "        \n",
    "    name_folder: str\n",
    "        Name of the folder in which the data is kept. NOTE! Do not forget to add an r before the string!!!\n",
    "        \n",
    "    tmax: int\n",
    "        Number of timesteps\n",
    "    \n",
    "    toutput: int\n",
    "        Which timesteps to give snapshots\n",
    "        \n",
    "        \n",
    "    Output:\n",
    "    --------\n",
    "    all_data: array\n",
    "        An array with all data for all particles and all snapshots. The order of the columns is \n",
    "        [mass, x, y, z, r, vx, vy, vz, v, r_search, mass_bk, status, acc_sofs x, acc_soft y, acc_soft z, \n",
    "        pot_tot, pot_soft, pot_ext]. Positions are in kpc and velocities in km/s\n",
    "        \n",
    "    header_values: array\n",
    "        An array with all data from the headers of the snapshots. The order of the columns is \n",
    "        [number of particles, time, x_offset, y_offset, z_offset, vx_offset, vy_offset, vz_offset]. \n",
    "        Positions are in kpc and velocities in km/s\n",
    "    \n",
    "    extra_data: array\n",
    "        Calculated extra data that is relevant for the analysis:\n",
    "        [half_mass_radius, r_mean_particles, r_mean_cluster, v_mean]\n",
    "        \n",
    "    hist_data: array\n",
    "        Data for making a cumulative mass vs radius plot \n",
    "        \n",
    "    \"\"\"\n",
    "    n_files = int((tmax/toutput) + 1)\n",
    "    \n",
    "    \n",
    "    # Fixing basic path\n",
    "    notebook_path = Path.cwd()\n",
    "\n",
    "    data_path = Path('Result_files')\n",
    "\n",
    "    total_path = os.path.join(notebook_path, data_path)\n",
    "    \n",
    "    # Importing header\n",
    "    header_values = np.empty((8, n_files)) # (quantities, timesteps)\n",
    "    extra_data = np.zeros((4, n_files)) # (quantities, timesteps)\n",
    "\n",
    "    for i in range(n_files):\n",
    "        header = PeTarDataHeader(total_path+f'/{name_folder}/{name_run}.{i}', \n",
    "                                       external_mode='galpy', snapshot_format='ascii')\n",
    "        header_values[0, i] = header.n # Number of particles\n",
    "        header_values[1, i] = header.time # Time\n",
    "        \n",
    "        x_mean = header.pos_offset[0] # Cluster mean x position\n",
    "        y_mean = header.pos_offset[1] # Cluster mean y position\n",
    "        z_mean = header.pos_offset[2] # Cluster mean z position\n",
    "        header_values[2, i] = x_mean/1000 # Convert to kpc \n",
    "        header_values[3, i] = y_mean/1000 # Convert to kpc\n",
    "        header_values[4, i] = z_mean/1000 # Convert to kpc\n",
    "        \n",
    "        r_mean_cluster = np.sqrt(x_mean**2 + y_mean**2 + z_mean**2)\n",
    "        \n",
    "        extra_data[2, i]\n",
    "        \n",
    "        # Convert from pm/Myr to km/s\n",
    "        vx_mean = (header.vel_offset[0] * u.pc/u.Myr).to(u.km/u.s).value # Cluster mean velocity in x position\n",
    "        vy_mean = (header.vel_offset[1] * u.pc/u.Myr).to(u.km/u.s).value # Cluster mean velocity in y position\n",
    "        vz_mean = (header.vel_offset[2] * u.pc/u.Myr).to(u.km/u.s).value # Cluster mean velocity in z position\n",
    "        header_values[5, i] = vx_mean \n",
    "        header_values[6, i] = vy_mean \n",
    "        header_values[7, i] = vz_mean\n",
    "        \n",
    "        v_mean_cluster = np.sqrt(vx_mean**2 + vy_mean**2 + vz_mean**2)\n",
    "        extra_data[3, i] = v_mean_cluster\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # Importing data into 3D array\n",
    "    all_data = np.empty((int(header_values[0, 0]), 21, n_files)) # (particles, quantities, timesteps)\n",
    "    n_particles = np.empty((n_files))\n",
    "    hist_data = np.zeros((2, int(header_values[0, 0]), n_files))\n",
    "    \n",
    "    for i in range(n_files):\n",
    "        # Importing the data\n",
    "        particles = Particle(external_mode='galpy', interupt_mode='bse')\n",
    "        particles.loadtxt(total_path+f'/{name_folder}/{name_run}.{i}', skiprows=1)\n",
    "        all_data[:, 0, i] = particles.mass # mass\n",
    "        \n",
    "        # Working with the positions\n",
    "        x = particles.pos[:, 0]/1000 # Convert to kpc\n",
    "        y = particles.pos[:, 1]/1000 # Convert to kpc\n",
    "        z = particles.pos[:, 2]/1000 # Convert to kpc\n",
    "        \n",
    "        # Adjusting the positions of the particles to the position of the cluster\n",
    "        all_data[:, 1, i] = x + header_values[2, i] # Galactic centre in origin frame\n",
    "        all_data[:, 2, i] = y + header_values[3, i]\n",
    "        all_data[:, 3, i] = z + header_values[4, i]\n",
    "        \n",
    "        r = np.sqrt(x**2 + y**2 + z**2) # Cluster centered around the origin frame\n",
    "        all_data[:, 4, i] = r\n",
    "        \n",
    "        extra_data[1, i] = np.mean(r, axis=0) # r_mean_particles\n",
    "    \n",
    "        #extra_data[1, i] = np.mean(x, axis=0) # x_mean\n",
    "        #extra_data[2, i] = np.mean(y, axis=0) # y_mean\n",
    "        #extra_data[3, i] = np.mean(z, axis=0) # z_mean\n",
    "        \n",
    "        # Working with the velocities and convert from pc/Myr to km/s\n",
    "        vx = (particles.vel[:, 0] * u.pc/u.Myr).to(u.km/u.s).value # vx\n",
    "        vy = (particles.vel[:, 1] * u.pc/u.Myr).to(u.km/u.s).value # vy\n",
    "        vz = (particles.vel[:, 2] * u.pc/u.Myr).to(u.km/u.s).value # vz\n",
    "        all_data[:, 5, i] = vx\n",
    "        all_data[:, 6, i] = vy\n",
    "        all_data[:, 7, i] = vz\n",
    "        \n",
    "        #extra_data[5, i] = np.mean(vx, axis=0) # vx_mean\n",
    "        #extra_data[6, i] = np.mean(vy, axis=0) # vy_mean\n",
    "        #extra_data[7, i] = np.mean(vz, axis=0) # vz_mean\n",
    "    \n",
    "        v = np.sqrt(vx**2 + vy**2 + vz**2)\n",
    "        all_data[:, 8, i] = v\n",
    "        \n",
    "        # The rest of the data\n",
    "        all_data[:, 9, i] = particles.r_search # neighbour searching radius\n",
    "        all_data[:, 10, i] = particles.id # particle id\n",
    "        all_data[:, 11, i] = particles.mass_bk # Artificial particle parameter\n",
    "        all_data[:, 12, i] = particles.status # Artificial particle parameter\n",
    "        all_data[:, 13, i] = particles.r_in # inner changeover radius\n",
    "        all_data[:, 14, i] = particles.r_out # outer changeover radius\n",
    "        all_data[:, 15, i] = particles.acc_soft[:, 0] # long-range acceleration in x\n",
    "        all_data[:, 16, i] = particles.acc_soft[:, 1] # long-range acceleration in y\n",
    "        all_data[:, 17, i] = particles.acc_soft[:, 2] # long-range acceleration in z\n",
    "        all_data[:, 18, i] = particles.pot # total potential\n",
    "        all_data[:, 19, i] = particles.pot_soft # long-range(?) potential\n",
    "        all_data[:, 20, i] = particles.pot_ext # external potential\n",
    "        \n",
    "        # Checking number of particles\n",
    "        n_particles[i] = len(particles.mass)\n",
    "        \n",
    "        # Half-mass radius\n",
    "        extra_data[0, i], hist_data[:, :, i] = halfmass_radius_cumsum(particles.mass, r)\n",
    "    \n",
    "    # Checking if the number of particles is the same throughout the simulation\n",
    "    n_part_same = np.all(n_particles == n_particles[0])\n",
    "    print(f'Number of particles is conserved: {n_part_same}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return all_data, header_values, extra_data, hist_data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26eb36",
   "metadata": {},
   "source": [
    "### Calculating means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98cb4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_calc(header_array):\n",
    "    v_mean = np.sqrt(header_array[-3, :]**2 +header_array[-2, :]**2 +header_array[-1, :]**2)\n",
    "    \n",
    "    r_mean = np.sqrt(header_array[2, :]**2 + header_array[3, :]**2 + header_array[4, :]**2)\n",
    "    \n",
    "    return v_mean, r_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d436b",
   "metadata": {},
   "source": [
    "### Half-mass radius function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b50e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfmass_radius_cumsum(masses, radii):\n",
    "    new_data_array = np.empty((len(masses), 2)) # Make an empty array\n",
    "    new_data_array[:, 0] = masses # Fills the first column with masses\n",
    "    new_data_array[:, 1] = radii # Fills the second columns with radii\n",
    "    sorted_array = np.array(sorted(new_data_array, key=lambda x:x[1])) # Sort the data according to the radii\n",
    "    \n",
    "    cumsum_mass = np.cumsum(sorted_array[:, 0]) # Calculate a cumulative sum of all masses, shape(n_particles)\n",
    "    \n",
    "    hist_data = np.vstack((cumsum_mass, sorted_array[:, 1]))\n",
    "    \n",
    "    Mtot = np.sum(masses)\n",
    "    half_mass = 0.5*Mtot\n",
    "    \n",
    "    difference = np.abs(cumsum_mass - half_mass)\n",
    "    closest_mass = np.min(difference)\n",
    "    \n",
    "    position = np.where(difference==closest_mass)[0]\n",
    "    \n",
    "    r_halfmass = sorted_array[position, 1][0]\n",
    "    \n",
    "    return r_halfmass, hist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e0ba8",
   "metadata": {},
   "source": [
    "### Interpolation of integrated mean orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dc15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_interpolate(orbit_data, laps):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ------------\n",
    "    orbit_data: 2d array\n",
    "        Data with Columns: x, y, z, vx, vy, vz, t, for orbit simulation\n",
    "        \n",
    "    laps: int\n",
    "        Number of times to do this\n",
    "        \n",
    "    Output:\n",
    "    -------\n",
    "    new_data: 4d array\n",
    "        Orbital positions with columns: x, y, z, vx, vy, vz, t, distance_in_stream\n",
    "    \"\"\"\n",
    "    for i in range(laps):\n",
    "        # Roll particles to get x1-x2, x2-x3, etc.\n",
    "        orbit_data_rolled = np.roll(orbit_data, shift=1, axis=0) \n",
    "        \n",
    "        # Delete first particle because of mismatch: xn-x1\n",
    "        data = np.delete(orbit_data, 0, axis=0) \n",
    "        data_rolled = np.delete(orbit_data_rolled, 0, axis=0)\n",
    "        #print(data_rolled[:10])\n",
    "        #print(data[:10])\n",
    "        \n",
    "        # Calculating middle point position: x, y, z\n",
    "        interp_pos = (data_rolled[:, 0:3] + data[:, 0:3])/2 \n",
    "        # Calculating average velocity between positions dx/dt\n",
    "        dx = data_rolled[:, 0:3] - data[:, 0:3]\n",
    "        dt = data_rolled[:, -1] - data[:, -1]\n",
    "        av_vel = dx/dt[:, np.newaxis]\n",
    "        # Calculating average time between points\n",
    "        av_t = (data_rolled[:, -1] + data[:, -1])/2\n",
    "        \n",
    "        # Length of data with added points in between\n",
    "        len_new_data = 2*len(orbit_data)-1\n",
    "        #print(len_new_data)\n",
    "\n",
    "        # x, y, z, vx, vy, vz, t\n",
    "        new_data = np.zeros((len_new_data, 7))\n",
    "        \n",
    "        # Adding data for new points\n",
    "        new_data[0::2, :] = orbit_data\n",
    "        new_data[1::2, 0:3] = interp_pos\n",
    "        new_data[1::2, 3:6] = av_vel\n",
    "        new_data[1::2, -1] = av_t\n",
    "        \n",
    "        orbit_data = new_data\n",
    "    \n",
    "    new_data_rolled = np.roll(new_data, shift=1, axis=0)\n",
    "    orb_dat = np.delete(new_data, 0, axis=0)\n",
    "    orb_dat_rolled = np.delete(new_data_rolled, 0, axis=0)\n",
    "\n",
    "    # Distance between consecutive points\n",
    "    dists = np.sqrt(np.sum((orb_dat_rolled[:, 0:3] - orb_dat[:, 0:3])**2, axis=1))\n",
    "    \n",
    "    distance_in_stream = np.zeros(len(new_data))\n",
    "    for i in range(1, len(dists)+1):\n",
    "        distance_in_stream[i] = np.sum(dists[:i+1])\n",
    "    \n",
    "    #print(dists[:10])\n",
    "    #print(np.shape(new_data), np.shape(dists_stream))\n",
    "    \n",
    "    # Gives columns x, y, z, vx, vy, vz, t, dists\n",
    "    new_data = np.concatenate((new_data, distance_in_stream[:, np.newaxis]), axis=1)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c66b5a3",
   "metadata": {},
   "source": [
    "### Finding stream crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e4f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_crossing(orbit_data, dist_upper_lim, vel_lower_lim):\n",
    "    orbit_positions = orbit_data[2:5, :].T # Shape: (Norb, 3)\n",
    "    orbit_velocities = orbit_data[5:8, :].T # Shape: (Norb, 3)\n",
    "    \n",
    "    # Calculating distances between all points in orbit\n",
    "    # Shape(Norb, Norb, 3)\n",
    "    distances_all_pos = orbit_positions[:, np.newaxis, :] - orbit_positions[np.newaxis, :, :] \n",
    "    # Shape(Norb, Norb)\n",
    "    r_diff_all_pos = np.sqrt(np.sum(distances_all_pos**2, axis=2))\n",
    "    \n",
    "    # Calculating difference between velocities between all points in orbit\n",
    "    # Shape(Norb, Norb, 3)\n",
    "    differences_all_vel = orbit_velocities[:, np.newaxis, :] - orbit_velocities[np.newaxis, :, :]\n",
    "    # Shape(Norb, Norb)\n",
    "    v_diff_all_pos = np.sqrt(np.sum(differences_all_vel**2, axis=2))\n",
    "    \n",
    "    # Making masks to find stream crossing\n",
    "    cross_pos_mask = (r_diff_all_pos>0)&(r_diff_all_pos<=dist_upper_lim)\n",
    "    cross_vel_mask = (v_diff_all_pos>=vel_lower_lim)\n",
    "    # Combining masks\n",
    "    crossings_mask = cross_pos_mask*cross_vel_mask\n",
    "    \n",
    "    # Finding indexes for the crossing points\n",
    "    positions = np.where(crossings_mask==True)[0]\n",
    "    \n",
    "    # Extracting position data for crossing\n",
    "    crossing_dat = orbit_positions[positions]\n",
    "    \n",
    "    return crossing_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8863ef9",
   "metadata": {},
   "source": [
    "### Stream alignment step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62602d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_alignment_step1(orbit_data, stream_data): # stream_crossing_pnt, crossing_dist_lim\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    orbit_data: 2d array\n",
    "        Data from mean orbit containing x, y, z, vx, vy, vz, inside_dists\n",
    "        \n",
    "    stream_data: 2d array\n",
    "        Data from final stream containing x, y, z, vx, vy, vz\n",
    "        \n",
    "    #stream_crossing_pnt: 2d array\n",
    "    #    Position where the streams cross each other\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculating distances to orbit\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    # Creating empty arrays to have data for stream distance and mean orbit distance\n",
    "    min_dist_to_orb = np.zeros((len(stream_data), 1))\n",
    "    dist_in_orb = np.zeros((len(stream_data), 1))\n",
    "    \n",
    "    # Extracting inside orbit distances from orbit data\n",
    "    inside_orbit_dists = orbit_data[:, -1]\n",
    "    \n",
    "    # Calculating differences between particles positions and all orbit positions (x, y, z)\n",
    "    # (N_part, 1, 3) - (n_orb, 3), skipping last column hence [:, :-1]\n",
    "    # Should give shape N_part, n_orb, 3\n",
    "    differences_to_orbit = stream_data[:, np.newaxis, 0:3] - orbit_data[:, 0:3]\n",
    "    print('Differences calculated')\n",
    "    \n",
    "    # Calculating sqrt(x² + y² + z²), has shape (N_part, n_orb, 1)\n",
    "    distances_to_orbit = np.sqrt(np.sum(differences_to_orbit**2, axis=2))\n",
    "    #print(np.shape(differences_to_orbit))\n",
    "    \n",
    "    \n",
    "    # Finding minimum distances to orbit and connecting to distance inside stream\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # Finding minimum distances, i.e. clostest orbit particle distances\n",
    "    min_dists = np.min(distances_to_orbit, axis=1)\n",
    "    #print(np.shape(min_dists))\n",
    "    \n",
    "    # Adding minimum distances to new array\n",
    "    min_dist_to_orb = min_dists\n",
    "    \n",
    "    # Finding the positions for the closest particles\n",
    "    pos_min_dists = np.argmin(distances_to_orbit, axis=1)\n",
    "    #print(np.shape(pos_min_dists))\n",
    "    \n",
    "    # Extracting inside stream distances from orbit data points\n",
    "    stream_distances = orbit_data[pos_min_dists, 6]\n",
    "    \n",
    "    # Adding inside stream distances second new array\n",
    "    dist_in_orb = stream_distances\n",
    "    \n",
    "    # Adding new columns to stream data\n",
    "    # Has shape x, y, z, vx, vy, vz, dist_closest_orb_part, dist_in_stream\n",
    "    new_stream_data = np.concatenate([stream_data, min_dist_to_orb[:, np.newaxis], dist_in_orb[:, np.newaxis]], \n",
    "                                     axis=1) \n",
    "        \n",
    "    return new_stream_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618b66b",
   "metadata": {},
   "source": [
    "### Stream alignment step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31a3f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_alignment_step2(orbit_data, new_stream_data):\n",
    "    \n",
    "    mean_dist_column = np.zeros((len(new_stream_data), 1))\n",
    "    # Has shape x, y, z, vx, vy, vz, distance to closest orbit particle, distance in stream, \n",
    "    # mean distance to mean orbit\n",
    "    aligned_stream_data = np.concatenate([new_stream_data, mean_dist_column], axis=1)\n",
    "\n",
    "    for i, st_dist in enumerate(orbit_data[:, -1]):\n",
    "        # Mask finding all particles at a certain distance inside the stream\n",
    "        particles_mask = (new_stream_data[:, -1]==st_dist)\n",
    "        # Extracting their minimum distances to the orbit\n",
    "        particles_orb_dists = new_stream_data[particles_mask, -2]\n",
    "        #print(len(particles_orb_dists))\n",
    "        # Calculating the mean in this position in the stream\n",
    "        mean_dist = np.mean(particles_orb_dists)\n",
    "        # Correcting the distance to the orbit with mean distance\n",
    "        aligned_stream_data[particles_mask, -1] = aligned_stream_data[particles_mask, 6] - mean_dist\n",
    "\n",
    "    \n",
    "    \n",
    "    return aligned_stream_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ce3e7",
   "metadata": {},
   "source": [
    "### Extracting stream shape properties function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9828b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_shape(orbit_data, aligned_stream_data):\n",
    "    \n",
    "    length = np.max(aligned_stream_data[:, 7]) - np.min(aligned_stream_data[:, 7])\n",
    "    width = np.zeros((len(orbit_data), 1))\n",
    "    part_dens = np.zeros((len(orbit_data), 1))\n",
    "    \n",
    "    # Calculating width and particle density along the stream\n",
    "    for i, st_dist in enumerate(orbit_data[:, -1]):\n",
    "        # Mask finding all particles at a certain distance inside the stream\n",
    "        particles_mask = (aligned_stream_data[:, -2]==st_dist)\n",
    "        \n",
    "        # Extracting their corrected minimum distances to the orbit\n",
    "        particles_corr_orb_dists = aligned_stream_data[particles_mask, -1]\n",
    "        #print(len(particles_corr_orb_dists))\n",
    "        \n",
    "        if len(particles_corr_orb_dists)==0:\n",
    "            part_dens[i] = 0\n",
    "            width[i] = 0\n",
    "            \n",
    "        else:\n",
    "            part_dens[i] = len(particles_corr_orb_dists)\n",
    "            width[i] = np.max(particles_corr_orb_dists) - np.min(particles_corr_orb_dists)\n",
    "        \n",
    "        \n",
    "    return length, width, part_dens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc647a8",
   "metadata": {},
   "source": [
    "### Calculate relative difference using bins function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8be600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_relative_difference(stream_prop, stream_data, comp_prop, comp_data, orbit_data, n_bins):\n",
    "    min_stream_length = np.min(orbit_data[:, -1])\n",
    "    max_stream_length = np.max(orbit_data[:, -1])\n",
    "    \n",
    "    # arange for setting bin width instead of number of bins\n",
    "    bin_edges = np.linspace(min_stream_length, max_stream_length, n_bins)\n",
    "    \n",
    "    bin_edges_rolled = np.roll(bin_edges, 1)\n",
    "    bin_edges_rolled_corr = np.delete(bin_edges_rolled, 0)\n",
    "    bin_edges_corr = np.delete(bin_edges, 0)\n",
    "    bin_positions = (bin_edges_rolled_corr + bin_edges_corr)/2\n",
    "    \n",
    "    relative_difference = []\n",
    "    standard_dev = []\n",
    "    \n",
    "    for i in range(1, len(bin_edges)):\n",
    "        #bin_mask_stream = (bin_edges[i-1]<=stream_data[:, -2])&(stream_data[:, -2]<bin_edges[i])\n",
    "        bin_mask_comp = (bin_edges[i-1]<=orbit_data[:, -1])&(orbit_data[:, -1]<bin_edges[i])\n",
    "        \n",
    "        property_stream = stream_prop[bin_mask_comp]\n",
    "        property_comp = comp_prop[bin_mask_comp]\n",
    "        \n",
    "        mean_prop_stream = np.median(property_stream)\n",
    "        mean_prop_comp = np.median(property_comp)\n",
    "        \n",
    "        rel_diff_mean = np.abs((mean_prop_comp - mean_prop_stream)/(mean_prop_comp))\n",
    "        relative_difference.append(rel_diff_mean)\n",
    "        \n",
    "        # Calculating standard deviation\n",
    "        stream_std = np.std(property_stream)\n",
    "        comp_std = np.std(property_comp)\n",
    "        \n",
    "        std_den = comp_std + stream_std\n",
    "        std_frac = rel_diff_mean*(std_den/(mean_prop_comp - mean_prop_stream) + comp_std/mean_prop_comp)\n",
    "        standard_dev.append(std_frac)\n",
    "        \n",
    "        \n",
    "    \n",
    "    relative_difference = np.array(relative_difference)\n",
    "    relative_difference[np.isnan(relative_difference)] = 0\n",
    "    relative_difference[np.isinf(relative_difference)] = np.max(relative_difference)\n",
    "    \n",
    "    standard_dev = np.array(standard_dev)\n",
    "    \n",
    "    result = np.concatenate([bin_positions[:, np.newaxis], relative_difference[:, np.newaxis], \n",
    "                             standard_dev[:, np.newaxis]], axis=1)\n",
    "    \n",
    "    return result #bin_positions, relative_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a322e",
   "metadata": {},
   "source": [
    "### Inertia tensor fcns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e7850",
   "metadata": {},
   "source": [
    "The intertia tensor for N particles is given by:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "I_{tensor} = \n",
    "\\begin{pmatrix} \n",
    "\\sum\\limits_{i=1}^N m_i (y_i^2 + z_i²) & -\\sum\\limits_{i=1}^N m_i x_i y_i & -\\sum\\limits_{i=1}^N m_i x_i z_i \\\\ \n",
    "-\\sum\\limits_{i=1}^N m_i x_i y_i & \\sum\\limits_{i=1}^N m_i (x_i^2 + z_i²) & -\\sum\\limits_{i=1}^N m_i y_i z_i \\\\\n",
    "-\\sum\\limits_{i=1}^N m_i x_i z_i & -\\sum\\limits_{i=1}^N m_i y_i z_i & \\sum\\limits_{i=1}^N m_i (x_i^2 + y_i²) \\\\\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "I_{xx} & -I_{xy} & -I_{xz} \\\\ \n",
    "-I_{yx} & I_{yy} & -I_{yz} \\\\\n",
    "-I_{zx} & -I_{zy} & I_{zz} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Iii(masses, j, k):\n",
    "    \"\"\"\n",
    "    masses: array\n",
    "        Contains masses of all particles. Shape: (N)\n",
    "        \n",
    "    j: array\n",
    "        Contains positions in j direction. E.g. if main axis is x, j=y and k=z\n",
    "    \"\"\"\n",
    "    coord = j**2 + k**2\n",
    "    tot = np.sum(masses*coord, axis=0)\n",
    "    return tot\n",
    "\n",
    "\n",
    "def Iij(masses, i, j, k):\n",
    "    coord1 = masses*i*j \n",
    "    coord2 = masses*i*k \n",
    "    \n",
    "    tot1 = np.sum(coord1, axis=0)\n",
    "    tot2 = np.sum(coord2, axis=0)\n",
    "    \n",
    "    return tot1, tot2\n",
    "\n",
    "\n",
    "def inertia_tensor(masses, pos):\n",
    "    \"\"\"\n",
    "    pos: Shape (N, 3), where 3 => x, y, z\n",
    "    \"\"\"\n",
    "    tensor = np.zeros((3, 3))\n",
    "    \n",
    "    for i in range(3):\n",
    "        coord = np.array([0, 1, 2])\n",
    "        indexes = np.delete(coord, i)\n",
    "        \n",
    "        tensor[i, i] = Iii(masses, pos[:, indexes[0]], pos[:, indexes[1]])\n",
    "        tens1, tens2 = Iij(masses, pos[:, i], pos[:, indexes[0]], pos[:, indexes[1]])\n",
    "        tensor[i, indexes[0]] = -tens1\n",
    "        tensor[i, indexes[1]] = -tens2\n",
    "    \n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3b331",
   "metadata": {},
   "source": [
    "### Calculating aspect ratios from inertia tensor eigenvalues function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961d97c",
   "metadata": {},
   "source": [
    "From equation (2) in Robles et al. 2015\n",
    "\n",
    "\\begin{equation}\n",
    "    a = \\sqrt{\\frac{5 (\\lambda_2 - \\lambda_1 + \\lambda_3)}{2M_{tot}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    b = \\sqrt{\\frac{5 (\\lambda_3 - \\lambda_2 + \\lambda_1)}{2M_{tot}}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    c = \\sqrt{\\frac{5 (\\lambda_1 - \\lambda_3 + \\lambda_2)}{2M_{tot}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2caf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_ratios(i1, i2, i3, Mtot):\n",
    "\n",
    "    a_num = 5*(i2 - i1 + i3)\n",
    "    b_num = 5*(i3 - i2 + i1)\n",
    "    c_num = 5*(i1 - i3 + i2)\n",
    "\n",
    "    den = 2*Mtot\n",
    "\n",
    "    a = np.sqrt(a_num/den)\n",
    "    b = np.sqrt(b_num/den)\n",
    "    c = np.sqrt(c_num/den)\n",
    "    \n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa16cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c07fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24e3576",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5073c",
   "metadata": {},
   "source": [
    "## Fiducial model run, large: 997967particles, 5Gyr forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b75946",
   "metadata": {},
   "source": [
    "Leo T-like progenitor in Boo III's orbit. Using data without uncertainties:\n",
    "\n",
    "- $M_{dyn} = 9 \\,$M$_{\\odot}$\n",
    "- $r_h = 153 \\,$pc\n",
    "- Maschberger 2012 IMF with masses above $2.955 \\,$M$_{\\odot}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b422a",
   "metadata": {},
   "source": [
    "%%time\n",
    "run_fid_large_mod_data, run_fid_large_mod_header, run_fid_large_mod_extra, fid_large_mod_hist_data = extract_data(r'fiducial_large_run_restart', \n",
    "                                                                                          r'Fiducial_large_run', 39, 1)\n",
    "\n",
    "print(run_fid_large_mod_data.shape)\n",
    "print(run_fid_large_mod_extra.shape)\n",
    "print(run_fid_large_mod_header.shape)\n",
    "print(run_fid_large_mod_header[:, -1])\n",
    "\n",
    "fid_large_mod_halfmass_r = run_fid_large_mod_extra[0, :]\n",
    "print(fid_large_mod_halfmass_r)\n",
    "\n",
    "print(np.max(fid_large_mod_halfmass_r))\n",
    "print(np.min(fid_large_mod_halfmass_r))\n",
    "\n",
    "v_mean_fid_large_mod, r_mean_fid_large_mod = means_calc(run_fid_large_mod_header)\n",
    "\n",
    "print(v_mean_fid_large_mod.shape)\n",
    "print(r_mean_fid_large_mod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dfa89ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#snapshots_btest = [0, 14, 27, -1]\n",
    "#snapshots_plot(run_fid_large_mod_data, snapshots_btest, 25.0e4, 25.0e4, (11, 20), 1, 'Fiducial_large_model', \n",
    "#               save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43757a55",
   "metadata": {},
   "source": [
    "## Trace forward of Boo III Orbit, 3 particles, 7Gyr forward in time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e11e01",
   "metadata": {},
   "source": [
    "run_petar_trace_forward_data, run_petar_trace_forward_header, run_petar_trace_forward_extra, petar_trace_forward_hist_data = extract_data(r'Trace_forward_run4_data', r'Trace_forward_run4', 1750, 1)\n",
    "\n",
    "print(run_petar_trace_forward_data.shape)\n",
    "print(run_petar_trace_forward_extra.shape)\n",
    "print(run_petar_trace_forward_header.shape)\n",
    "\n",
    "petar_trace_forward_halfmass_r = run_petar_trace_forward_extra[0, :]\n",
    "#print(petar_trace_forward_halfmass_r)\n",
    "\n",
    "print(np.max(petar_trace_forward_halfmass_r))\n",
    "print(np.min(petar_trace_forward_halfmass_r))\n",
    "\n",
    "v_mean_petar_trace_forward, r_mean_petar_trace_forward = means_calc(run_petar_trace_forward_header)\n",
    "\n",
    "print(v_mean_petar_trace_forward.shape)\n",
    "print(r_mean_petar_trace_forward.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55730990",
   "metadata": {},
   "source": [
    "### Plotting orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871eb544",
   "metadata": {},
   "source": [
    "fig_orb= plt.figure(figsize=(10, 8))\n",
    "ax_orb = fig_orb.add_subplot(projection='3d', computed_zorder=False)\n",
    "\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "\n",
    "x_bulge = 1500 * np.outer(np.cos(u), np.sin(v))\n",
    "y_bulge = 1500 * np.outer(np.sin(u), np.sin(v))\n",
    "z_bulge = 1500 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "x_disc = 14490 * np.outer(np.cos(u), np.sin(v))\n",
    "y_disc = 14490 * np.outer(np.sin(u), np.sin(v))\n",
    "z_disc = 300 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "#Before: 40:109\n",
    "ax_orb.plot(run_petar_trace_forward_header[2, 650:], run_petar_trace_forward_header[3, 650:], \n",
    "            run_petar_trace_forward_header[4, 650:], color='b')\n",
    "\n",
    "sc = ax_orb.scatter(run_petar_trace_forward_header[2, 650:], run_petar_trace_forward_header[3, 650:], \n",
    "            run_petar_trace_forward_header[4, 650:], c=run_petar_trace_forward_header[1, 650:], cmap='spring')\n",
    "\n",
    "plt.colorbar(sc)\n",
    "ax_orb.set_xlabel('x [pc]', labelpad=15)\n",
    "ax_orb.set_ylabel('y [pc]', labelpad=15)\n",
    "ax_orb.set_zlabel('z [pc]', labelpad=5)\n",
    "ax_orb.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_orb.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_orb.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_orb.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_orb.zaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_orb.zaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "ax_orb.plot_surface(x_bulge, y_bulge, z_bulge, color='grey', alpha=0.5)\n",
    "ax_orb.plot_surface(x_disc, y_disc, z_disc, color='grey', alpha=0.5)\n",
    "\n",
    "ax_orb.view_init(4, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c084dbf",
   "metadata": {},
   "source": [
    "### Finding crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a34f20",
   "metadata": {},
   "source": [
    "orbit_crossing = stream_crossing(run_petar_trace_forward_header[:, 650:], 5e2, 1e2)\n",
    "print(orbit_crossing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b39c5",
   "metadata": {},
   "source": [
    "orbit_pos = run_petar_trace_forward_header[2:5, 650:].T\n",
    "\n",
    "difference_to_crossing = orbit_pos - orbit_crossing[0, :]\n",
    "distance_to_crossing = np.sqrt(np.sum(difference_to_crossing**2, axis=1))\n",
    "\n",
    "close_orbit_pos = distance_to_crossing<=5e3\n",
    "close_pos = orbit_pos[close_orbit_pos]\n",
    "print(np.shape(close_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67738a",
   "metadata": {},
   "source": [
    "### Plotting particles close to crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbec523",
   "metadata": {},
   "source": [
    "fig_orb2 = plt.figure(figsize=(10, 8))\n",
    "ax_orb2 = fig_orb2.add_subplot(projection='3d', computed_zorder=False)\n",
    "\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "\n",
    "x_bulge = 1500 * np.outer(np.cos(u), np.sin(v))\n",
    "y_bulge = 1500 * np.outer(np.sin(u), np.sin(v))\n",
    "z_bulge = 1500 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "x_disc = 14490 * np.outer(np.cos(u), np.sin(v))\n",
    "y_disc = 14490 * np.outer(np.sin(u), np.sin(v))\n",
    "z_disc = 300 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "#Before: 40:109\n",
    "#ax_orb.plot(run_petar_trace_forward_header[2, 650:], run_petar_trace_forward_header[3, 650:], \n",
    "#run_petar_trace_forward_header[4, 650:], color='b')\n",
    "\n",
    "sc = ax_orb2.scatter(run_petar_trace_forward_header[2, 650:], run_petar_trace_forward_header[3, 650:], \n",
    "                     run_petar_trace_forward_header[4, 650:], c=run_petar_trace_forward_header[1, 650:], \n",
    "                     cmap='spring', s=10)\n",
    "\n",
    "plt.colorbar(sc)\n",
    "\n",
    "ax_orb2.scatter(orbit_crossing[0, 0], orbit_crossing[0, 1], orbit_crossing[0, 2], c='b', marker='x', s=20)\n",
    "ax_orb2.scatter(close_pos[:, 0], close_pos[:, 1], close_pos[:, 2], c='r', s=10)\n",
    "\n",
    "\n",
    "ax_orb2.set_xlabel('x [pc]', labelpad=15)\n",
    "ax_orb2.set_ylabel('y [pc]', labelpad=15)\n",
    "ax_orb2.set_zlabel('z [pc]', labelpad=5)\n",
    "ax_orb2.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_orb2.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_orb2.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_orb2.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_orb2.zaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_orb2.zaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "ax_orb2.plot_surface(x_bulge, y_bulge, z_bulge, color='grey', alpha=0.5)\n",
    "ax_orb2.plot_surface(x_disc, y_disc, z_disc, color='grey', alpha=0.5)\n",
    "\n",
    "#ax_orb2.set_xlim(xmin=-0.0e5, xmax=0.4e5)\n",
    "#ax_orb2.set_ylim(ymin=-0.1e5, ymax=0.0e5)\n",
    "#ax_orb2.set_zlim(zmin=-0.05e5, zmax=0.05e5)\n",
    "\n",
    "ax_orb2.view_init(4, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7498d",
   "metadata": {},
   "source": [
    "### Constructing orbit data array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d37695",
   "metadata": {},
   "source": [
    "orbit_position = run_petar_trace_forward_header[2:5, 650:].T # To get shape (N,x)\n",
    "orbit_velocity = run_petar_trace_forward_header[5:8, 650:].T # To get shape (N,x)\n",
    "orbit_times = run_petar_trace_forward_header[1, 650:].T # To get shape (N,x)\n",
    "\n",
    "#gets columns (x, y, z, vx, vy, vz, t)\n",
    "orbit_data = np.concatenate([orbit_position, orbit_velocity, orbit_times[:, np.newaxis]], axis=1)\n",
    "\n",
    "print(np.shape(orbit_data)) # Expect shape n,7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dece10",
   "metadata": {},
   "source": [
    "### Interpolating orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008ef66",
   "metadata": {},
   "source": [
    "interpolated_orbit = easy_interpolate(orbit_data, 2)\n",
    "print(np.shape(interpolated_orbit))\n",
    "#print(interpolated_orbit[:20, 3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7a08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd89824",
   "metadata": {},
   "source": [
    "### Testing stream alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db224084",
   "metadata": {},
   "source": [
    "#Has columns x, y, z, vx, vy, vz\n",
    "stream_data = run_fid_large_mod_data[:, 1:7, -1]\n",
    "orbital_data = np.delete(interpolated_orbit, 6, axis=1) # Removing time from orbital data as it is not needed\n",
    "print(np.shape(orbital_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532d556",
   "metadata": {},
   "source": [
    "aligned_stream1 = stream_alignment_step1(orbital_data, stream_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601783e8",
   "metadata": {},
   "source": [
    "## Developing alignment function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26598ef4",
   "metadata": {},
   "source": [
    "min_dist_to_orb = np.zeros((len(stream_data), 1))\n",
    "dist_in_orb = np.zeros((len(stream_data), 1))\n",
    "    \n",
    "#Extracting inside orbit distances from orbit data\n",
    "inside_orbit_dists = orbit_data[:, -1]\n",
    "    \n",
    "#Calculating differences between particles positions and all orbit positions (x, y, z)\n",
    "#(N_part, 1, 3) - (n_orb, 3), skipping last column hence [:, :-1]\n",
    "#Should give shape N_part, n_orb, 3\n",
    "differences_to_orbit = stream_data[:, np.newaxis, 0:3] - orbit_data[:, 0:3]\n",
    "print('Differences calculated')\n",
    "    \n",
    "#Calculating sqrt(x² + y² + z²), has shape (N_part, n_orb, 1)\n",
    "distances_to_orbit = np.sqrt(np.sum(differences_to_orbit**2, axis=2))\n",
    "#print(np.shape(differences_to_orbit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae31a1d",
   "metadata": {},
   "source": [
    "### Finding particles close to crossing point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d71c70",
   "metadata": {},
   "source": [
    "####Doing separate calculations for crossing particles\n",
    "#Calculating distance to stream crossing point\n",
    "difference_to_crossing = positions - orbit_crossing[0, :]\n",
    "distance_to_crossing = np.sqrt(np.sum(difference_to_crossing**2, axis=1))\n",
    "print(np.min(distance_to_crossing))\n",
    "\n",
    "#Making a mask to find particles closest to the crossing point\n",
    "close_orbit_pos = (distance_to_crossing<=5e3) # 5e3\n",
    "#Extracting particles that are close to crossing, Shape: (N_cross_part, 6)\n",
    "close_crossing_particles_pos = positions[close_orbit_pos, :]\n",
    "print(len(close_crossing_particles_pos))\n",
    "\n",
    "#Extracting velocities from stream data\n",
    "velocities = run_fid_large_mod_data[:, 4:7, -1]\n",
    "#Finding velocity data for particles close to crossing point\n",
    "close_crossing_particles_vel = velocities[close_orbit_pos, :]\n",
    "\n",
    "\n",
    "#Which rows to find the close to crossing particles\n",
    "#distances_to_orbit[close_pos_rows, :] gives me the values for close_crossing_particles\n",
    "close_pos_rows = np.where(close_orbit_pos==True)[0] #, close_pos_cols\n",
    "#print(close_pos_rows)\n",
    "print(np.shape(close_pos_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32abaa6",
   "metadata": {},
   "source": [
    "### Finding wrong velocity directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4090e",
   "metadata": {},
   "source": [
    "def scalar_product(a, b):\n",
    "    # a shape: (N_part, 3)\n",
    "    # b shape: (N_orb, 3)\n",
    "        \n",
    "    if len(a)==1:\n",
    "        x = a[:, 0]*b[:, 0]\n",
    "        y = a[:, 1]*b[:, 1]\n",
    "        z = a[:, 2]*b[:, 2]\n",
    "        all_pos = np.concatenate([x[:, np.newaxis], y[:, np.newaxis], z[:, np.newaxis]], axis=1)\n",
    "        summation = x+y+z #np.sum(all_pos, axis=1)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        multiplication = a[:, np.newaxis, :]*b[:, :]\n",
    "        # Shapes (N_part, N_orb, 1)\n",
    "        x = a[:, np.newaxis, 0]*b[:, 0]\n",
    "        y = a[:, np.newaxis, 1]*b[:, 1]\n",
    "        z = a[:, np.newaxis, 2]*b[:, 2]\n",
    "\n",
    "        all_pos = np.concatenate([x[:, :, np.newaxis], y[:, :, np.newaxis], z[:, :, np.newaxis]], axis=2)\n",
    "\n",
    "        summation = np.sum(all_pos, axis=2) #multiplication\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e1f92",
   "metadata": {},
   "source": [
    "#Checking velocity directions through division, vx, vy and vz directions positive=> same direction\n",
    "#Should give shape N_close_part, n_orb, 3\n",
    "velocity_directions = close_crossing_particles_vel[:, np.newaxis, :]/interpolated_orbit[:, 3:6]\n",
    "#print(velocity_directions)\n",
    "#print('Velocity directions calculated')\n",
    "\n",
    "#Gives me shape N_cross_part, n_orb\n",
    "wrong_direction_mask = np.any(velocity_directions<0, axis=2)\n",
    "#print(wrong_direction_mask[:10, :])\n",
    "\n",
    "#right_direction_mask = np.all(velocity_directions>0, axis=2)\n",
    "#print(velocity_directions[right_direction_mask])\n",
    "#print(len(velocity_directions[right_direction_mask]))\n",
    "\n",
    "scalar_prod = scalar_product(close_crossing_particles_vel, interpolated_orbit[:, 3:6])\n",
    "print(f'Shape scalar product {np.shape(scalar_prod)}')\n",
    "stream_vector_lengths = np.sqrt(np.sum(close_crossing_particles_vel**2, axis=1))\n",
    "orbit_vector_lengths = np.sqrt(np.sum(interpolated_orbit[:, 3:6]**2, axis=1))\n",
    "print(f'Shape stream vector lengths {np.shape(stream_vector_lengths)}')\n",
    "print(f'Shape orbit vector lengths {np.shape(orbit_vector_lengths)}')\n",
    "print(f'Orbit vector lenghts {orbit_vector_lengths}')\n",
    "\n",
    "one_part = close_crossing_particles_vel[0, :]\n",
    "print(np.shape(one_part))\n",
    "scalar = scalar_product(one_part[np.newaxis, :], interpolated_orbit[:, 3:6])\n",
    "#scalar = np.dot(one_part[np.newaxis, :], interpolated_orbit[:, 3:6])\n",
    "print(scalar)\n",
    "length_one_part = np.sqrt(np.sum(one_part))\n",
    "print(length_one_part)\n",
    "div = scalar/(length_one_part*orbit_vector_lengths)\n",
    "print(length_one_part*orbit_vector_lengths)\n",
    "print(div)\n",
    "angle = np.arccos(div)\n",
    "print(angle)\n",
    "\n",
    "#In radians\n",
    "angles = np.arccos(scalar_prod/(stream_vector_lengths[:, np.newaxis]*orbit_vector_lengths[np.newaxis, :]))\n",
    "print(np.shape(angles))\n",
    "print(f'{np.min(angles) * 180/np.pi} deg', np.min(angles))\n",
    "print(f'{np.max(angles) * 180/np.pi} deg', np.max(angles))\n",
    "#print(angles* 180/np.pi)\n",
    "\n",
    "#print(80*np.pi/180)\n",
    "\n",
    "min_ang_pos = np.argmin(angles, axis=1)\n",
    "print(np.shape(min_ang_pos))\n",
    "#wrong_direction_mask =  angles>1.34\n",
    "#Makes distances with wrong directions super large\n",
    "#distaces_to_orbit[close_pos_rows, :][wrong_direction_mask] = 1e20\n",
    "\n",
    "\n",
    "distances_to_orbit[close_pos_rows, :][:, min_ang_pos] = distances_to_orbit[close_pos_rows, :][:, min_ang_pos]/100\n",
    "####\n",
    "#print(np.shape(distances_to_orbit[close_pos_rows, :][wrong_direction_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f291c",
   "metadata": {},
   "source": [
    "### Finding minimum distances to orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117662b",
   "metadata": {},
   "source": [
    "#Finding minimum distances to orbit and connecting to distance inside stream\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#Finding minimum distances, i.e. clostest orbit particle distances\n",
    "min_dists = np.min(distances_to_orbit, axis=1)\n",
    "#print(np.shape(min_dists))\n",
    "    \n",
    "#Adding minimum distances to new array\n",
    "min_dist_to_orb = min_dists\n",
    "    \n",
    "#Finding the positions for the closest particles\n",
    "pos_min_dists = np.argmin(distances_to_orbit, axis=1)\n",
    "print(np.shape(pos_min_dists))\n",
    "    \n",
    "#Extracting inside stream distances from orbit data points\n",
    "stream_distances = orbit_data[pos_min_dists, 6]\n",
    "    \n",
    "#Adding inside stream distances second new array\n",
    "dist_in_orb = stream_distances\n",
    "    \n",
    "#Adding new columns to stream data\n",
    "#Has shape x, y, z, vx, vy, vz, dist_closest_orb_part, dist_in_stream\n",
    "new_stream_data = np.concatenate([stream_data, min_dist_to_orb[:, np.newaxis], dist_in_orb[:, np.newaxis]], \n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa1b60",
   "metadata": {},
   "source": [
    "### Plotting aligned stream part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c40ae",
   "metadata": {},
   "source": [
    "fig_t1, ax_t1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax_t1.scatter(aligned_stream1[:, -1], aligned_stream1[:, -2], c='b', s=5)\n",
    "#ax_t1.scatter(aligned_stream_st1[:, 7], aligned_stream_st1[:, 6], c='b', s=5)\n",
    "\n",
    "ax_t1.set_title('Stream aligned with mean orbit')\n",
    "ax_t1.set_xlabel('Distance inside stream [pc]')\n",
    "ax_t1.set_ylabel('Distance to mean orbit [pc]')\n",
    "\n",
    "ax_t1.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t1.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t1.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t1.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6223aa4",
   "metadata": {},
   "source": [
    "### Checking if the crossing is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6405e92",
   "metadata": {},
   "source": [
    "fig_t2 = plt.figure(figsize=(10, 8))\n",
    "ax_t2 = fig_t2.add_subplot(projection='3d', computed_zorder=False)\n",
    "\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "\n",
    "x_bulge = 1500 * np.outer(np.cos(u), np.sin(v))\n",
    "y_bulge = 1500 * np.outer(np.sin(u), np.sin(v))\n",
    "z_bulge = 1500 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "x_disc = 14490 * np.outer(np.cos(u), np.sin(v))\n",
    "y_disc = 14490 * np.outer(np.sin(u), np.sin(v))\n",
    "z_disc = 300 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    \n",
    "\n",
    "\n",
    "#Plotting stream coloured with stream distance\n",
    "sc = ax_t2.scatter(run_fid_large_mod_data[:, 1, -1], run_fid_large_mod_data[:, 2, -1], \n",
    "                     run_fid_large_mod_data[:, 3, -1], c=aligned_stream1[:, -1], cmap='spring', s=10, zorder=0,\n",
    "                     label='Stream data') #alpha=0.5, \n",
    "\n",
    "\n",
    "cbar = plt.colorbar(sc, label='Stream distances [pc]', format=ScalarFormatter(useMathText=True))\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "#ax_orb3.scatter(close_crossing_particles_pos[:, 0], close_crossing_particles_pos[:, 1],\n",
    "#close_crossing_particles_pos[:, 2], c='r', label='Particles close to crossing')\n",
    "\n",
    "\n",
    "\n",
    "ax_t2.set_xlabel('x [pc]', labelpad=15)\n",
    "ax_t2.set_ylabel('y [pc]', labelpad=15)\n",
    "ax_t2.set_zlabel('z [pc]', labelpad=5)\n",
    "ax_t2.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t2.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t2.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t2.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t2.zaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t2.zaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "ax_t2.plot_surface(x_bulge, y_bulge, z_bulge, color='grey', alpha=0.5)\n",
    "ax_t2.plot_surface(x_disc, y_disc, z_disc, color='grey', alpha=0.5)\n",
    "\n",
    "ax_t2.set_xlim(xmin=-0.0e5, xmax=0.4e5)\n",
    "ax_t2.set_ylim(ymin=-0.05e5, ymax=0.05e5)\n",
    "ax_t2.set_zlim(zmin=-0.05e5, zmax=0.05e5)\n",
    "\n",
    "ax_t2.view_init(4, 55)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53aa31",
   "metadata": {},
   "source": [
    "### Corrected alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bfc03",
   "metadata": {},
   "source": [
    "aligned_stream2 = stream_alignment_step2(orbital_data, aligned_stream1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6f8c5",
   "metadata": {},
   "source": [
    "fig_t3, ax_t3 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax_t3.scatter(aligned_stream2[:, -2], aligned_stream2[:, -1], c='b', s=5)\n",
    "\n",
    "ax_t3.set_title('Corrected alignment')\n",
    "ax_t3.set_xlabel('Distance inside stream [pc]')\n",
    "ax_t3.set_ylabel('Distance to mean orbit [pc]')\n",
    "\n",
    "ax_t3.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t3.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t3.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t3.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a5db60",
   "metadata": {},
   "source": [
    "### Testing extracting shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2c258",
   "metadata": {},
   "source": [
    "length, width, part_dens = stream_shape(orbital_data, aligned_stream2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a071dc",
   "metadata": {},
   "source": [
    "print(length)\n",
    "#print(width)\n",
    "#print(part_dens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd25e0",
   "metadata": {},
   "source": [
    "fig_t4, ax_t4 = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "ax_t4[0].scatter(orbital_data[:, -1], width, c='b', s=10)\n",
    "\n",
    "ax_t4[0].set_title('Width along stream')\n",
    "ax_t4[0].set_xlabel('Distance inside stream [pc]')\n",
    "ax_t4[0].set_ylabel('Stream width [pc]')\n",
    "ax_t4[0].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t4[0].xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t4[0].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t4[0].yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "\n",
    "ax_t4[1].scatter(orbital_data[:, -1], part_dens, c='b', s=10)\n",
    "\n",
    "ax_t4[1].set_title('Particle density along stream')\n",
    "ax_t4[1].set_xlabel('Distance inside stream [pc]')\n",
    "ax_t4[1].set_ylabel('Particle density')\n",
    "ax_t4[1].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t4[1].xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t4[1].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t4[1].yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24285200",
   "metadata": {},
   "source": [
    "fig_t5, ax_t5 = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "ax_t5.scatter(orbital_data[:, -1], part_dens, c='b', s=10)\n",
    "\n",
    "ax_t5.set_title('Particle density along stream')\n",
    "ax_t5.set_xlabel('Distance inside stream [pc]')\n",
    "ax_t5.set_ylabel('Particle density')\n",
    "ax_t5.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t5.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax_t5.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax_t5.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "ax_t5.set_ylim(ymin=0, ymax=0.4e3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d078a3e",
   "metadata": {},
   "source": [
    "## Angular momentum calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c08ba",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\overrightarrow{L} = \\overrightarrow{r} \\times m\\overrightarrow{v}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa5850",
   "metadata": {},
   "source": [
    "positions = run_fid_large_mod_data[:, 1:4, -1] #(Particles, values)\n",
    "#np.savetxt('Large_fiducial_model_positions.txt', positions, delimiter=',')\n",
    "#print(np.shape(positions))\n",
    "velocities = run_fid_large_mod_data[:, 4:7, -1] #(Particles, values)\n",
    "#print(np.shape(velocities))\n",
    "masses = run_fid_large_mod_data[:, 0, -1]\n",
    "#print(np.shape(masses))\n",
    "\n",
    "\n",
    "mv = masses[:, np.newaxis]*velocities\n",
    "angular_momenta = np.cross(positions, mv)\n",
    "ang_mom_tot = np.sqrt(angular_momenta[:, 0]**2 + angular_momenta[:, 1]**2 + angular_momenta[:, 2]**2)\n",
    "\n",
    "matrix_6d = np.empty([997967, 7])\n",
    "matrix_6d[:, :3] = positions\n",
    "matrix_6d[:, 3:6] = angular_momenta\n",
    "matrix_6d[:, -1] = ang_mom_tot\n",
    "\n",
    "ang_mom_pos_mask = angular_momenta>0\n",
    "ang_mom_min_mask = angular_momenta<0\n",
    "\n",
    "ang_mom_dir = np.empty([997967, 3])\n",
    "ang_mom_dir[ang_mom_pos_mask] = 1\n",
    "ang_mom_dir[ang_mom_min_mask] = -1\n",
    "\n",
    "\n",
    "dist_6d = np.sqrt(positions[:, 0]**2 + positions[:, 1]**2 + positions[:, 2]**2 + velocities[:, 0]**2 + velocities[:, 1]**2 + velocities[:, 2]**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f64c4",
   "metadata": {},
   "source": [
    "print(np.shape(run_fid_large_mod_data[:,1, -1]))\n",
    "print(np.shape(angular_momenta[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eea033",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 2,figsize=(14, 6))\n",
    "\n",
    "ellipse = mpl.patches.Ellipse((0, 0), width=30000, height=300, color='b', alpha=1) # Disc (x, z) view\n",
    "circle1 = mpl.patches.Circle((0, 0), 1500, color='b', alpha=1) # Bulge (x, z) view\n",
    "\n",
    "arrow_numbers = 10\n",
    "colormap=mpl.cm.Reds\n",
    "color_vals = angular_momenta[::arrow_numbers, 0]\n",
    "arrow_map = mpl.cm.ScalarMappable(cmap=colormap, norm=None)\n",
    "arrow_map.set_array(color_vals)\n",
    "#arrow_map.set_clim(vmin=-2.0e9, vmax=2.0e9)\n",
    "\n",
    "\n",
    "sc = ax[0].scatter(run_fid_large_mod_data[:,1,-1], run_fid_large_mod_data[:,3,-1], c=dist_6d, alpha=0.3, s=1, cmap='spring')\n",
    "#arrows0 = ax[0].quiver(run_fid_large_mod_data[::arrow_numbers,1, -1], run_fid_large_mod_data[::arrow_numbers,3, -1], \n",
    "#                       ang_mom_dir[::arrow_numbers, 0], ang_mom_dir[::arrow_numbers, 2], scale_units='width', \n",
    "#                       scale=50, width=0.0075, color=colormap(color_vals), alpha=1) \n",
    "\n",
    "plt.colorbar(sc, ax=ax[0], label='6D distance')\n",
    "#plt.colorbar(arrow_map, ax=ax[0], label='x-dir')\n",
    "#ax[0].add_patch(circle1)\n",
    "#ax[0].add_patch(ellipse)\n",
    "#ax[0].set_xlim(xmin=-0.7e5, xmax=0.8e5) #xmin=-0.7e5, xmax=0.8e5\n",
    "#ax[0].set_ylim(ymin=-1.0e5, ymax=1.75e5)\n",
    "ax[0].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax[0].xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax[0].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax[0].yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "#ax[0].set_title('')\n",
    "ax[0].set_xlabel('x [pc]')\n",
    "ax[0].set_ylabel('z [pc]')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[1].scatter(run_fid_large_mod_data[:,1, -1], run_fid_large_mod_data[:,3, -1], c='b', alpha=0.3, s=1)\n",
    "arrows1 = ax[1].quiver(run_fid_large_mod_data[::arrow_numbers,1, -1], \n",
    "                       run_fid_large_mod_data[::arrow_numbers,3, -1], ang_mom_dir[::arrow_numbers, 0], \n",
    "                       ang_mom_dir[::arrow_numbers, 2], scale_units='width', scale=50, \n",
    "                       width=0.0075, color=colormap(color_vals), alpha=1) \n",
    "\n",
    "plt.colorbar(arrow_map, ax=ax[1], label='x-dir')\n",
    "ax[1].set_xlim(xmin=0.25e5, xmax=0.5e5)\n",
    "ax[1].set_ylim(ymin=-0.75e5, ymax=0.0e5)\n",
    "ax[1].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax[1].xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax[1].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax[1].yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "#ax[1].set_title('')\n",
    "ax[1].set_xlabel('x [pc]')\n",
    "ax[1].set_ylabel('z [pc]')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./Plots/.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e5268",
   "metadata": {},
   "source": [
    "### 3D arrow plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27370d4",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a302a94",
   "metadata": {},
   "source": [
    "y_pos, vy_vel, vz_vel = zip(*sorted(zip(positions[:, 2], velocities[:, 1], velocities[:, 2])))\n",
    "\n",
    "y_pos = np.array(y_pos)\n",
    "vy_vel = np.array(vy_vel)\n",
    "vz_vel = np.array(vz_vel)\n",
    "\n",
    "vel_data = np.array([vy_vel, vz_vel])\n",
    "vel_data = vel_data.transpose()\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=7)\n",
    "y_poly = polynomial_features.fit_transform(y_pos[:, np.newaxis])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(y_poly, vel_data)\n",
    "vy_poly_pred = model.predict(y_poly)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(vel_data,vy_poly_pred)) #root mean square error\n",
    "r2 = r2_score(vel_data,vy_poly_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-squared\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66990edf",
   "metadata": {},
   "source": [
    "fig3d = plt.figure(figsize=(12, 10))\n",
    "ax3d = fig3d.add_subplot(projection='3d', computed_zorder=False)\n",
    "\n",
    "\n",
    "#colormap=mpl.cm.Reds\n",
    "#arrow_map = mpl.cm.ScalarMappable(cmap=colormap, norm=None)\n",
    "#arrow_map.set_array(angular_momenta[::100, 0])\n",
    "\n",
    "\n",
    "ax3d.scatter(run_fid_large_mod_data[:,2,-1], run_fid_large_mod_data[:,5,-1], run_fid_large_mod_data[:,6,-1], \n",
    "           c='b', alpha=0.1, s=1, zorder=-100)\n",
    "\n",
    "ax3d.plot(y_pos, vel_data[:, 0], vel_data[:, 1], color='r', alpha=0.5)\n",
    "\n",
    "#ax3d.quiver(run_fid_large_mod_data[::100,1,-1], run_fid_large_mod_data[::100,2,-1], \n",
    "#            run_fid_large_mod_data[::100,3,-1], ang_mom_dir[::100,0], ang_mom_dir[::100,1],\n",
    "#            ang_mom_dir[::100,2], length=10000, color=colormap(angular_momenta[::100, 0]), zorder=1000) #cmap='spring', angular_momenta[::10, 0]\n",
    "\n",
    "#plt.colorbar(arrow_map, label='x-dir')\n",
    "#ax3d.set_xlim(xmin=-0.7e5, xmax=0.8e5)\n",
    "#ax3d.set_ylim(ymin=-0.5e5, ymax=1.5e5)\n",
    "#ax3d.set_zlim(zmin=-1.0e5, zmax=1.75e5)\n",
    "ax3d.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax3d.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax3d.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax3d.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "ax3d.zaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax3d.zaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "#ax3d.set_title('')\n",
    "ax3d.set_xlabel('y [pc]', labelpad=15)\n",
    "ax3d.set_ylabel('vy', labelpad=15)\n",
    "ax3d.set_zlabel('vz',labelpad=5)\n",
    "\n",
    "ax3d.view_init(4, 45) #(elevation, rotation)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746beff",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#%matplotlib inline\n",
    "fig3d2 = plt.figure(figsize=(12, 12))\n",
    "\n",
    "# 1:x, 2:y, 3:z, 4:vx, 5:vy, 6:vz\n",
    "x_label = 'y'\n",
    "y_label = 'vy'\n",
    "z_label = 'vz'\n",
    "\n",
    "x = 2\n",
    "y = 5\n",
    "z = 6\n",
    "\n",
    "angles = [15, 45, 75, 145]\n",
    "azimuths = [4, 4, 4, 4]\n",
    "\n",
    "for i in range(4):\n",
    "    ax3d2 = fig3d2.add_subplot(2, 2, i+1, projection='3d', computed_zorder=False)\n",
    "    ax3d2.scatter(run_fid_large_mod_data[:,x, -1], run_fid_large_mod_data[:,y, -1], \n",
    "                  run_fid_large_mod_data[:, z, -1], c='b', s=1, alpha=0.5)\n",
    "\n",
    "    ax3d2.set_xlabel(x_label)\n",
    "    ax3d2.set_ylabel(y_label)\n",
    "    ax3d2.set_zlabel(z_label)\n",
    "    ax3d2.set_title(f'Azimuth: {azimuths[i]}, Angle: {angles[i]}')\n",
    "\n",
    "    ax3d2.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax3d2.xaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "    ax3d2.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax3d2.yaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "    ax3d2.zaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax3d2.zaxis.get_major_formatter().set_powerlimits((0, 0))\n",
    "\n",
    "    ax3d2.view_init(azimuths[i], angles[i])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1841de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_petar_btest_data, run_petar_btest_header, run_petar_btest_extra, petar_btest_hist_data = extract_data(r'btest2_data', r'Petar_back_test2', 125, 1)\n",
    "\n",
    "#print(run_petar_btest_data.shape)\n",
    "#print(run_petar_btest_extra.shape)\n",
    "#print(run_petar_btest_header.shape)\n",
    "\n",
    "#petar_btest_halfmass_r = run_petar_btest_extra[0, :]\n",
    "#print(petar_btest_halfmass_r)\n",
    "\n",
    "#print(np.max(petar_btest_halfmass_r))\n",
    "#print(np.min(petar_btest_halfmass_r))\n",
    "\n",
    "#v_mean_petar_btest, r_mean_petar_btest = means_calc(run_petar_btest_header)\n",
    "\n",
    "#print(v_mean_petar_btest.shape)\n",
    "#print(r_mean_petar_btest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "467e5d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anim_disc(run_petar_btest_data, run_petar_btest_header, tstep=8, nsteps=125, lims=5.0e4, fsize=(10, 10), \n",
    "#          tx=-25000, ty=24000, format_type='gif', fps=6, run='btest2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "694f0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anim_3d(run_petar_btest_data, run_petar_btest_header, tstep=8, nsteps=125, lims=5.0e4, fsize=(10, 10), \n",
    "#        marker_size=20, tx=-30500, ty=35500, tz=35500, format_type='gif', fps=6, run='btest2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "322342ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_at_centre_data, run_at_centre_header, centre_extra_data, centre_hist_data = extract_data(r'mcluster_at_centre_data', r'Trialrun_1000part_at_centre', 30, 1)\n",
    "#print(run_at_centre_data.shape)\n",
    "#print(centre_hist_data.shape)\n",
    "#print(centre_extra_data.shape)\n",
    "\n",
    "#centre_halfmass_late = centre_extra_data[0, 6]\n",
    "#centre_halfmass_early = centre_extra_data[0, 1]\n",
    "#print(centre_halfmass)\n",
    "#print(centre_hist_data[0, -1, 6])\n",
    "#print(np.sum(run_at_centre_data[:, 0, 6]))\n",
    "#print()\n",
    "\n",
    "\n",
    "#run_above_disc_data, run_above_disc_header, above_extra_data, above_hist_data = extract_data(r'mcluster_above_disc_data', r'Trialrun_1000part_above_disc', 6, 1)\n",
    "#print(run_above_disc_data.shape)\n",
    "#print(above_hist_data.shape)\n",
    "#print(above_extra_data.shape)\n",
    "\n",
    "#above_halfmass_late = above_extra_data[0, 6]\n",
    "#above_halfmass_early = above_extra_data[0, 1]\n",
    "#print(above_halfmass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa196431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_fig1, testax1 = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "\n",
    "#testax1[0].minorticks_on()\n",
    "#testax1[0].plot(centre_hist_data[1, :, 1], centre_hist_data[0, :, 1], color='b')\n",
    "#testax1.scatter(sorted_data[position[0], 7], cumsum_mass[position[0]], color='r')\n",
    "\n",
    "#testax1[0].plot(above_hist_data[1, :, 1], above_hist_data[0, :, 1], color='r')\n",
    "#testax1.scatter(sorted_data2[position2[0], 7], cumsum_mass2[position2[0]], color='g')\n",
    "#testax1[0].set_xlabel('r')\n",
    "#testax1[0].set_ylabel('Sum of M')\n",
    "#testax1[0].set_title('Cumsum hist early')\n",
    "#testax1[0].axvline(centre_halfmass_early, color='aqua', linestyle='dashed')\n",
    "#testax1[0].axvline(above_halfmass_early, color='tomato', linestyle='dashed')\n",
    "#testax1[0].grid(which='both')\n",
    "\n",
    "\n",
    "#testax1[1].minorticks_on()\n",
    "#testax1[1].plot(centre_hist_data[1, :, 6], centre_hist_data[0, :, 6], color='b')\n",
    "#testax1.scatter(sorted_data[position[0], 7], cumsum_mass[position[0]], color='r')\n",
    "\n",
    "#testax1[1].plot(above_hist_data[1, :, 6], above_hist_data[0, :, 6], color='r')\n",
    "#testax1.scatter(sorted_data2[position2[0], 7], cumsum_mass2[position2[0]], color='g')\n",
    "#testax1[1].set_xlabel('r')\n",
    "#testax1[1].set_ylabel('Sum of M')\n",
    "#testax1[1].set_title('Cumsum hist late')\n",
    "#testax1[1].axvline(centre_halfmass_late, color='aqua', linestyle='dashed')\n",
    "#testax1[1].axvline(above_halfmass_late, color='tomato', linestyle='dashed')\n",
    "#testax1[1].grid(which='both')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c457663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "114600fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_data, my_header = extract_data(r'mcluster_at_centre_data', r'Trialrun_1000part_at_centre', 30, 1)\n",
    "\n",
    "#print(np.shape(my_data))\n",
    "#print(halfmass_radius_cumsum(my_data[:, 0, 0], my_data[:, 7, 0]))\n",
    "#print(my_extra_data[0, :])\n",
    "#print(my_extra_data.shape)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "202fe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_t1 = my_data[:, :, 6]\n",
    "#print(np.shape(data_t1))\n",
    "#print(type(data_t1))\n",
    "#print(data_t1[:, 7])\n",
    "#print(data_t1[:, 0])\n",
    "#print()\n",
    "#print(min(data_t1[:, 7]))\n",
    "#print(max(data_t1[:, 7]))\n",
    "#print()\n",
    "\n",
    "\n",
    "#my_r = my_data[:, 7, 0]\n",
    "\n",
    "#sorted_data = np.array(sorted(data_t1, key=lambda x:x[7]))\n",
    "#print(np.shape(sorted_data))\n",
    "#print(type(sorted_data))\n",
    "#print(sorted_data[:,7])\n",
    "#print(sorted_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "31bc6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumsum_mass = np.cumsum(sorted_data[:, 0])\n",
    "#print(cumsum_mass[3200:3300])\n",
    "#print(len(cumsum_mass))\n",
    "#print(np.sum(data_t1[:, 0]))\n",
    "#print(cumsum_mass[-1])\n",
    "#Mtot = cumsum_mass[-1]\n",
    "#half_mass = 0.5*Mtot\n",
    "#print(f'{half_mass = }')\n",
    "\n",
    "#half_mass_diff = np.abs(cumsum_mass - half_mass)\n",
    "#closest = np.min(half_mass_diff)\n",
    "#print(closest)\n",
    "#position = np.where(half_mass_diff==closest)[0]\n",
    "#print(half_mass_diff[position])\n",
    "#print(cumsum_mass[position])\n",
    "#print(sorted_data[position, 7], position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c7d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6590c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_test = 6.17909780681924\n",
      "difference = 808.6573131521109\n",
      "r_test = 9.268646710228861\n",
      "difference = 110.85027228494118\n",
      "r_test = 9.268646710228861\n",
      "difference = 110.85027228494118\n",
      "\n",
      "9.268646710228861\n"
     ]
    }
   ],
   "source": [
    "#r_halfmass = halfmass_radius_finder(my_data[:, 0, 0], my_data[:, 7, 0])\n",
    "#print()\n",
    "#print(r_halfmass)\n",
    "#print()\n",
    "#r_halfmass2 = halfmass_radius(my_data[:, 0, 5], my_radii)\n",
    "#print()\n",
    "#print(r_halfmass2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82562ace",
   "metadata": {},
   "source": [
    "# Unused functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfmass_radius_finder(masses, radii):\n",
    "    Mtot = np.sum(masses)\n",
    "    \n",
    "    r_max = np.max(radii)\n",
    "    r_test = 0.5*r_max\n",
    "    r_tests = []\n",
    "    r_tests.append(r_test)\n",
    "    n_part_inside = []\n",
    "    \n",
    "    masses_inside = masses[radii<=r_test]\n",
    "    Mtot_inside = np.sum(masses_inside)\n",
    "    n_part_inside.append(len(masses_inside))\n",
    "    #print(len(masses_inside))\n",
    "    difference = 0.5*Mtot-Mtot_inside\n",
    "    \n",
    "    if np.abs(difference)<=1e-1:\n",
    "        return r_test\n",
    "    \n",
    "    else:\n",
    "        if difference<0:\n",
    "            r_test = r_test - 0.5*r_test\n",
    "            r_tests.append(r_test)\n",
    "            \n",
    "        elif difference>0:\n",
    "            r_test = r_test + 0.5*r_test\n",
    "            r_tests.append(r_test)\n",
    "            \n",
    "        \n",
    "        masses_inside = masses[radii<=r_test]\n",
    "        n_part_inside.append(len(masses_inside))\n",
    "        #print(len(masses_inside))\n",
    "        Mtot_inside = np.sum(masses_inside)\n",
    "        difference = 0.5*Mtot-Mtot_inside\n",
    "        it = 1\n",
    "        while np.abs(difference)>1e-1:\n",
    "            print(f'{r_test = }')\n",
    "            print(f'{difference = }')\n",
    "            if difference<0:\n",
    "                r_test = r_test - 0.5*np.abs(r_test-r_tests[it-1])\n",
    "                \n",
    "                r_tests[it] = r_test\n",
    "                r_tests.append(r_test)\n",
    "                \n",
    "                masses_inside = masses[radii<=r_test]\n",
    "                #print(len(masses_inside))\n",
    "                n_part_inside.append(len(masses_inside))\n",
    "                if len(masses_inside)==n_part_inside[it-1]:\n",
    "                    return r_test\n",
    "                    break\n",
    "                Mtot_inside = np.sum(masses_inside)\n",
    "                difference = 0.5*Mtot-Mtot_inside\n",
    "                it = it+1\n",
    "                \n",
    "                \n",
    "            elif difference>0:\n",
    "                r_test = r_test + 0.5*np.abs(r_test-r_tests[it-1])\n",
    "                \n",
    "                r_tests[it] = r_test\n",
    "                r_tests.append(r_test)\n",
    "                masses_inside = masses[radii<=r_test]\n",
    "                #print(len(masses_inside))\n",
    "                n_part_inside.append(len(masses_inside))\n",
    "                if len(masses_inside)==n_part_inside[it-1]:\n",
    "                    return r_test\n",
    "                    break\n",
    "                Mtot_inside = np.sum(masses_inside)\n",
    "                difference = 0.5*Mtot-Mtot_inside\n",
    "                it = it+1\n",
    "                \n",
    "        return r_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
