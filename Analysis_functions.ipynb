{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b3c142",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88df0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.table import QTable\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/home/emelie/Desktop/Codes/PETAR/PeTar-master/tools/')\n",
    "from analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78ef65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'xtick.labelsize':13, 'ytick.labelsize':13, 'axes.titlesize':16, \n",
    "                     'axes.grid':True, 'axes.labelsize':15, 'legend.fontsize':13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1904a9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cccc457",
   "metadata": {},
   "source": [
    "## Half-mass radius function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9ff586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfmass_radius_cumsum(masses, radii):\n",
    "    new_data_array = np.empty((len(masses), 2)) # Make an empty array\n",
    "    new_data_array[:, 0] = masses # Fills the first column with masses\n",
    "    new_data_array[:, 1] = radii # Fills the second columns with radii\n",
    "    sorted_array = np.array(sorted(new_data_array, key=lambda x:x[1])) # Sort the data according to the radii\n",
    "    \n",
    "    cumsum_mass = np.cumsum(sorted_array[:, 0]) # Calculate a cumulative sum of all masses, shape(n_particles)\n",
    "    \n",
    "    hist_data = np.vstack((cumsum_mass, sorted_array[:, 1]))\n",
    "    \n",
    "    Mtot = np.sum(masses)\n",
    "    half_mass = 0.5*Mtot\n",
    "    \n",
    "    difference = np.abs(cumsum_mass - half_mass)\n",
    "    closest_mass = np.min(difference)\n",
    "    \n",
    "    position = np.where(difference==closest_mass)[0]\n",
    "    \n",
    "    r_halfmass = sorted_array[position, 1][0]\n",
    "    \n",
    "    return r_halfmass, hist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41807cad",
   "metadata": {},
   "source": [
    "## Energy function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aeba71",
   "metadata": {},
   "source": [
    "**NOTE!**\n",
    "Copied from computational n-body simulation, it does however not account for the potential. Fix/check!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbb41fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(x, y, z, vx, vy, vz, masses):\n",
    "    m = np.array(masses).flatten() * u.Msun # shape=(N, )\n",
    "    \n",
    "    v = np.sqrt(vx**2 + vy**2 + vz**2)\n",
    "    \n",
    "    # Fixing position vectors i and j, gives shape (N, 1, 3) and (1, N, 3)\n",
    "    r = np.transpose(np.vstack((x, y, z)))    \n",
    "    r_i = r[:, np.newaxis, :] * u.au\n",
    "    r_j = r[np.newaxis, :, :] * u.au\n",
    "    \n",
    "    \n",
    "    # Calculate distances\n",
    "    d = r_i - r_j \n",
    "    \n",
    "    #print(f'{d = }')\n",
    "    \n",
    "    \n",
    "    absd = np.linalg.norm(d, axis=2)\n",
    "    abs_d = absd[:, :, np.newaxis]\n",
    "    \n",
    "    #print(f'{abs_d = }')\n",
    "    \n",
    "    \n",
    "    \n",
    "    division = 1/(2*abs_d)\n",
    "    \n",
    "    # Replaces infs with 0\n",
    "    division[np.isinf(division)] = 0\n",
    "    \n",
    "\n",
    "    P = ((-c.G*np.matmul(m, division)).flatten()).value # shape=(N, )\n",
    "    \n",
    "    #print(f'{P = }')\n",
    "    \n",
    "    for i in range(len(P)):\n",
    "        if P[i] == -np.inf:\n",
    "            P[i] = 0\n",
    "    \n",
    "    \n",
    "    K = v**2/2 # shape=(N, )\n",
    "    \n",
    "    inside = P + K # shape=(N, )\n",
    "    #print(f'{inside = }')\n",
    "    \n",
    "    E_tot = np.matmul(m, inside).value\n",
    "    \n",
    "\n",
    "    \n",
    "    return E_tot\n",
    "    \n",
    "    \n",
    "def energy_conservation(E, E_in):\n",
    "    return np.abs(E - E_in)/np.abs(E_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bbbe4a",
   "metadata": {},
   "source": [
    "## The function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9639e7",
   "metadata": {},
   "source": [
    "**Things I want to put into the function**\n",
    "\n",
    "- Number of timesteps\n",
    "- Times for output\n",
    "- Name of run\n",
    "- Folder for the data files\n",
    "- Check that the number of particles is conserved!\n",
    "\n",
    "\n",
    "**The output of the function**\n",
    "\n",
    "- mean $x$, $y$, $z$\n",
    "- mean $r = \\sqrt{x² + y² + z²}$\n",
    "- mean $v_x$, $v_y$, $v_z$\n",
    "- halfmass radius\n",
    "- momentum over time?\n",
    "- energy over time?\n",
    "- headers\n",
    "- \\# of part conserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a0efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b58f453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(name_run, name_folder, tmax, toutput):\n",
    "    \"\"\"\n",
    "    Extracts data from petar snapshot files and checks the data\n",
    "    ------------------------------------------------------------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    name_run: str\n",
    "        Name of the run. NOTE! Do not forget to add an r before the string!!!\n",
    "        \n",
    "    name_folder: str\n",
    "        Name of the folder in which the data is kept. NOTE! Do not forget to add an r before the string!!!\n",
    "        \n",
    "    tmax: int\n",
    "        Number of timesteps\n",
    "    \n",
    "    toutput: int\n",
    "        Which timesteps to give snapshots\n",
    "        \n",
    "        \n",
    "    Output:\n",
    "    --------\n",
    "    all_data: array\n",
    "        An array with all data for all particles and all snapshots. The order of the columns is \n",
    "        [mass, x, y, z, r, vx, vy, vz, v, r_search, mass_bk, status, acc_sofs x, acc_soft y, acc_soft z, \n",
    "        pot_tot, pot_soft, pot_ext].\n",
    "        \n",
    "    header_values: array\n",
    "        An array with all data from the headers of the snapshots. The order of the columns is \n",
    "        [number of particles, time, x_offset, y_offset, z_offset, vx_offset, vy_offset, vz_offset]\n",
    "    \n",
    "    extra_data: array\n",
    "        Calculated extra data that is relevant for the analysis:\n",
    "        [half_mass_radius, r_mean_particles, r_mean_cluster, v_mean]\n",
    "        \n",
    "    hist_data: array\n",
    "        Data for making a cumulative mass vs radius plot \n",
    "        \n",
    "    \"\"\"\n",
    "    n_files = int((tmax/toutput) + 1)\n",
    "    \n",
    "    \n",
    "    # Fixing basic path\n",
    "    notebook_path = Path.cwd()\n",
    "\n",
    "    data_path = Path('Result_files')\n",
    "\n",
    "    total_path = os.path.join(notebook_path, data_path)\n",
    "    \n",
    "    # Importing header\n",
    "    header_values = np.empty((8, n_files)) # (quantities, timesteps)\n",
    "    extra_data = np.zeros((4, n_files)) # (quantities, timesteps)\n",
    "\n",
    "    for i in range(n_files):\n",
    "        header = PeTarDataHeader(total_path+f'/{name_folder}/{name_run}.{i}', \n",
    "                                       external_mode='galpy', snapshot_format='ascii')\n",
    "        header_values[0, i] = header.n # Number of particles\n",
    "        header_values[1, i] = header.time # Time\n",
    "        \n",
    "        x_mean = header.pos_offset[0] # Cluster mean x position\n",
    "        y_mean = header.pos_offset[1] # Cluster mean y position\n",
    "        z_mean = header.pos_offset[2] # Cluster mean z position\n",
    "        header_values[2, i] = x_mean \n",
    "        header_values[3, i] = y_mean\n",
    "        header_values[4, i] = z_mean\n",
    "        \n",
    "        r_mean_cluster = np.sqrt(x_mean**2 + y_mean**2 + z_mean**2)\n",
    "        \n",
    "        extra_data[2, i]\n",
    "        \n",
    "        \n",
    "        vx_mean = header.vel_offset[0] # Cluster mean velocity in x position\n",
    "        vy_mean = header.vel_offset[1] # Cluster mean velocity in y position\n",
    "        vz_mean = header.vel_offset[2] # Cluster mean velocity in z position\n",
    "        header_values[5, i] = vx_mean \n",
    "        header_values[6, i] = vy_mean \n",
    "        header_values[7, i] = vz_mean\n",
    "        \n",
    "        v_mean_cluster = np.sqrt(vx_mean**2 + vy_mean**2 + vz_mean**2)\n",
    "        extra_data[3, i] = v_mean_cluster\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # Importing data into 3D array\n",
    "    all_data = np.empty((int(header_values[0, 0]), 21, n_files)) # (particles, quantities, timesteps)\n",
    "    n_particles = np.empty((n_files))\n",
    "    hist_data = np.zeros((2, int(header_values[0, 0]), n_files))\n",
    "    \n",
    "    for i in range(n_files):\n",
    "        # Importing the data\n",
    "        particles = Particle(external_mode='galpy', interupt_mode='bse')\n",
    "        particles.loadtxt(total_path+f'/{name_folder}/{name_run}.{i}', skiprows=1)\n",
    "        all_data[:, 0, i] = particles.mass # mass\n",
    "        \n",
    "        # Working with the positions\n",
    "        x = particles.pos[:, 0] \n",
    "        y = particles.pos[:, 1] \n",
    "        z = particles.pos[:, 2] \n",
    "        \n",
    "        # Adjusting the positions of the particles to the position of the cluster\n",
    "        all_data[:, 1, i] = x + header_values[2, i] # Galactic centre in origin frame\n",
    "        all_data[:, 2, i] = y + header_values[3, i]\n",
    "        all_data[:, 3, i] = z + header_values[4, i]\n",
    "        \n",
    "        r = np.sqrt(x**2 + y**2 + z**2) # Cluster centered around the origin frame\n",
    "        all_data[:, 4, i] = r\n",
    "        \n",
    "        extra_data[1, i] = np.mean(r, axis=0) # r_mean_particles\n",
    "    \n",
    "        #extra_data[1, i] = np.mean(x, axis=0) # x_mean\n",
    "        #extra_data[2, i] = np.mean(y, axis=0) # y_mean\n",
    "        #extra_data[3, i] = np.mean(z, axis=0) # z_mean\n",
    "        \n",
    "        # Working with the velocities\n",
    "        vx = particles.vel[:, 0] # vx\n",
    "        vy = particles.vel[:, 1] # vy\n",
    "        vz = particles.vel[:, 2] # vz\n",
    "        all_data[:, 5, i] = vx\n",
    "        all_data[:, 6, i] = vy\n",
    "        all_data[:, 7, i] = vz\n",
    "        \n",
    "        #extra_data[5, i] = np.mean(vx, axis=0) # vx_mean\n",
    "        #extra_data[6, i] = np.mean(vy, axis=0) # vy_mean\n",
    "        #extra_data[7, i] = np.mean(vz, axis=0) # vz_mean\n",
    "    \n",
    "        v = np.sqrt(vx**2 + vy**2 + vz**2)\n",
    "        all_data[:, 8, i] = v\n",
    "        \n",
    "        # The rest of the data\n",
    "        all_data[:, 9, i] = particles.r_search # neighbour searching radius\n",
    "        all_data[:, 10, i] = particles.id # particle id\n",
    "        all_data[:, 11, i] = particles.mass_bk # Artificial particle parameter\n",
    "        all_data[:, 12, i] = particles.status # Artificial particle parameter\n",
    "        all_data[:, 13, i] = particles.r_in # inner changeover radius\n",
    "        all_data[:, 14, i] = particles.r_out # outer changeover radius\n",
    "        all_data[:, 15, i] = particles.acc_soft[:, 0] # long-range acceleration in x\n",
    "        all_data[:, 16, i] = particles.acc_soft[:, 1] # long-range acceleration in y\n",
    "        all_data[:, 17, i] = particles.acc_soft[:, 2] # long-range acceleration in z\n",
    "        all_data[:, 18, i] = particles.pot # total potential\n",
    "        all_data[:, 19, i] = particles.pot_soft # long-range(?) potential\n",
    "        all_data[:, 20, i] = particles.pot_ext # external potential\n",
    "        \n",
    "        # Checking number of particles\n",
    "        n_particles[i] = len(particles.mass)\n",
    "        \n",
    "        # Half-mass radius\n",
    "        extra_data[0, i], hist_data[:, :, i] = halfmass_radius_cumsum(particles.mass, r)\n",
    "    \n",
    "    # Checking if the number of particles is the same throughout the simulation\n",
    "    n_part_same = np.all(n_particles == n_particles[0])\n",
    "    print(f'Number of particles is conserved: {n_part_same}')\n",
    "    \n",
    "    # Calculating useful quantities    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Conservation of momentum\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Conservation of energy\n",
    "    # E(t)-E(0)/E(0)?\n",
    "    \n",
    "    \n",
    "    \n",
    "    return all_data, header_values, extra_data, hist_data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27ed1a",
   "metadata": {},
   "source": [
    "## Calculating means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_calc(header_array):\n",
    "    v_mean = np.sqrt(header_array[-3, :]**2 +header_array[-2, :]**2 +header_array[-1, :]**2)\n",
    "    \n",
    "    r_mean = np.sqrt(header_array[2, :]**2 + header_array[3, :]**2 + header_array[4, :]**2)\n",
    "    \n",
    "    return v_mean, r_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b493e",
   "metadata": {},
   "source": [
    "## Plotting Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658a0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_plots(which, header_array, mean, t_max, run, fig_width=14, fig_height=10, save=True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    which: str\n",
    "            If the plots should contain velocities or positions\n",
    "            \n",
    "    header_array: array\n",
    "            Array with header values: id, N, t, x, y, z, vx, vy, vz\n",
    "            \n",
    "    mean: float\n",
    "            Mean value\n",
    "            \n",
    "    t_max: int or float\n",
    "            Maximum time of simulation\n",
    "            \n",
    "    run: str\n",
    "            Name of run\n",
    "            \n",
    "    fig_width: int or float\n",
    "            Width of figure\n",
    "            \n",
    "    fig_height: int or float\n",
    "            Height of figure\n",
    "            \n",
    "    save: str\n",
    "            If figure should be saved\n",
    "    \n",
    "    \"\"\"\n",
    "    text = t_max/10\n",
    "    tmin = 0-text\n",
    "    tmax = t_max+text\n",
    "    \n",
    "    \n",
    "    if which=='vel':\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(fig_width, fig_height))\n",
    "\n",
    "        ax[0,0].plot(header_array[1, :], mean, color='b', marker='o')\n",
    "\n",
    "        ax[0,0].set_xlabel('Time [Myr]')\n",
    "        ax[0,0].set_ylabel(r'$v_{mean}$ [km/s]')\n",
    "        ax[0,0].set_title('Mean velocity per timestep')\n",
    "        ax[0,0].set_xlim(tmin, tmax)\n",
    "\n",
    "\n",
    "\n",
    "        ax[0,1].plot(header_array[1, :], header_array[-3, :], color='b', marker='o')\n",
    "\n",
    "        ax[0,1].set_xlabel('Time [Myr]')\n",
    "        ax[0,1].set_ylabel(r'$v_{mean, x}$ [km/s]')\n",
    "        ax[0,1].set_title('Mean velocity in x per timestep')\n",
    "        ax[0,1].axhline(0, color='k', zorder=0)\n",
    "        ax[0,1].set_xlim(tmin, tmax)\n",
    "\n",
    "\n",
    "        ax[1,0].plot(header_array[1, :], header_array[-2, :], color='b', marker='o')\n",
    "\n",
    "        ax[1,0].set_xlabel('Time [Myr]')\n",
    "        ax[1,0].set_ylabel(r'$v_{mean, y}$ [km/s]')\n",
    "        ax[1,0].set_title('Mean velocity in y per timestep')\n",
    "        ax[1,0].axhline(0, color='k', zorder=0)\n",
    "        ax[1,0].set_xlim(tmin, tmax)\n",
    "\n",
    "\n",
    "\n",
    "        ax[1,1].plot(header_array[1, :], header_array[-1, :], color='b', marker='o')\n",
    "\n",
    "        ax[1,1].set_xlabel('Time [Myr]')\n",
    "        ax[1,1].set_ylabel(r'$v_{mean, z}$ [km/s]')\n",
    "        ax[1,1].set_title('Mean velocity in z per timestep')\n",
    "        ax[1,1].axhline(0, color='k', zorder=0)\n",
    "        ax[1,1].set_xlim(tmin, tmax)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(f'Velocity_plots_{run}.png', bbox_inches='tight')\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if which=='pos':\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(fig_width, fig_height))\n",
    "\n",
    "        ax[0,0].plot(header_array[1, :], mean, color='b', marker='o')\n",
    "\n",
    "        ax[0,0].set_xlabel('Time [Myr]')\n",
    "        ax[0,0].set_ylabel(r'$r_{mean}$ [pc]')\n",
    "        ax[0,0].set_title('Mean r per timestep')\n",
    "        ax[0,0].set_xlim(tmin, tmax)\n",
    "        #ax[0,0].set_ylim(ymin=-1000, ymax=23000)\n",
    "\n",
    "\n",
    "\n",
    "        ax[0,1].plot(header_array[1, :], header_array[2, :], color='b', marker='o')\n",
    "\n",
    "        ax[0,1].set_xlabel('Time [Myr]')\n",
    "        ax[0,1].set_ylabel(r'$x_{mean}$ [pc]')\n",
    "        ax[0,1].set_title('Mean x per timestep')\n",
    "        ax[0,1].axhline(0, color='k', zorder=0)\n",
    "        ax[0,1].set_xlim(tmin, tmax)\n",
    "        #ax[0,1].set_ylim(ymin=-21000, ymax=21000)\n",
    "\n",
    "\n",
    "        ax[1,0].plot(header_array[1, :], header_array[3, :], color='b', marker='o')\n",
    "\n",
    "        ax[1,0].set_xlabel('Time [Myr]')\n",
    "        ax[1,0].set_ylabel(r'$y_{mean}$ [pc]')\n",
    "        ax[1,0].set_title('Mean y per timestep')\n",
    "        ax[1,0].axhline(0, color='k', zorder=0)\n",
    "        ax[1,0].set_xlim(tmin, tmax)\n",
    "        #ax[1,0].set_ylim(ymin=-21000, ymax=21000)\n",
    "\n",
    "\n",
    "\n",
    "        ax[1,1].plot(header_array[1, :], header_array[4, :], color='b', marker='o')\n",
    "\n",
    "        ax[1,1].set_xlabel('Time [Myr]')\n",
    "        ax[1,1].set_ylabel(r'$z_{mean}$ [pc]')\n",
    "        ax[1,1].set_title('Mean z per timestep')\n",
    "        ax[1,1].axhline(0, color='k', zorder=0)\n",
    "        ax[1,1].set_xlim(tmin, tmax)\n",
    "        #ax[1,1].set_ylim(ymin=-21000, ymax=21000)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(f'Position_plots_{run}.png', bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86dbff",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "322342ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_at_centre_data, run_at_centre_header, centre_extra_data, centre_hist_data = extract_data(r'mcluster_at_centre_data', r'Trialrun_1000part_at_centre', 30, 1)\n",
    "#print(run_at_centre_data.shape)\n",
    "#print(centre_hist_data.shape)\n",
    "#print(centre_extra_data.shape)\n",
    "\n",
    "#centre_halfmass_late = centre_extra_data[0, 6]\n",
    "#centre_halfmass_early = centre_extra_data[0, 1]\n",
    "#print(centre_halfmass)\n",
    "#print(centre_hist_data[0, -1, 6])\n",
    "#print(np.sum(run_at_centre_data[:, 0, 6]))\n",
    "#print()\n",
    "\n",
    "\n",
    "#run_above_disc_data, run_above_disc_header, above_extra_data, above_hist_data = extract_data(r'mcluster_above_disc_data', r'Trialrun_1000part_above_disc', 6, 1)\n",
    "#print(run_above_disc_data.shape)\n",
    "#print(above_hist_data.shape)\n",
    "#print(above_extra_data.shape)\n",
    "\n",
    "#above_halfmass_late = above_extra_data[0, 6]\n",
    "#above_halfmass_early = above_extra_data[0, 1]\n",
    "#print(above_halfmass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa196431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_fig1, testax1 = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "\n",
    "#testax1[0].minorticks_on()\n",
    "#testax1[0].plot(centre_hist_data[1, :, 1], centre_hist_data[0, :, 1], color='b')\n",
    "#testax1.scatter(sorted_data[position[0], 7], cumsum_mass[position[0]], color='r')\n",
    "\n",
    "#testax1[0].plot(above_hist_data[1, :, 1], above_hist_data[0, :, 1], color='r')\n",
    "#testax1.scatter(sorted_data2[position2[0], 7], cumsum_mass2[position2[0]], color='g')\n",
    "#testax1[0].set_xlabel('r')\n",
    "#testax1[0].set_ylabel('Sum of M')\n",
    "#testax1[0].set_title('Cumsum hist early')\n",
    "#testax1[0].axvline(centre_halfmass_early, color='aqua', linestyle='dashed')\n",
    "#testax1[0].axvline(above_halfmass_early, color='tomato', linestyle='dashed')\n",
    "#testax1[0].grid(which='both')\n",
    "\n",
    "\n",
    "#testax1[1].minorticks_on()\n",
    "#testax1[1].plot(centre_hist_data[1, :, 6], centre_hist_data[0, :, 6], color='b')\n",
    "#testax1.scatter(sorted_data[position[0], 7], cumsum_mass[position[0]], color='r')\n",
    "\n",
    "#testax1[1].plot(above_hist_data[1, :, 6], above_hist_data[0, :, 6], color='r')\n",
    "#testax1.scatter(sorted_data2[position2[0], 7], cumsum_mass2[position2[0]], color='g')\n",
    "#testax1[1].set_xlabel('r')\n",
    "#testax1[1].set_ylabel('Sum of M')\n",
    "#testax1[1].set_title('Cumsum hist late')\n",
    "#testax1[1].axvline(centre_halfmass_late, color='aqua', linestyle='dashed')\n",
    "#testax1[1].axvline(above_halfmass_late, color='tomato', linestyle='dashed')\n",
    "#testax1[1].grid(which='both')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c457663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "114600fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_data, my_header = extract_data(r'mcluster_at_centre_data', r'Trialrun_1000part_at_centre', 30, 1)\n",
    "\n",
    "#print(np.shape(my_data))\n",
    "#print(halfmass_radius_cumsum(my_data[:, 0, 0], my_data[:, 7, 0]))\n",
    "#print(my_extra_data[0, :])\n",
    "#print(my_extra_data.shape)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "202fe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_t1 = my_data[:, :, 6]\n",
    "#print(np.shape(data_t1))\n",
    "#print(type(data_t1))\n",
    "#print(data_t1[:, 7])\n",
    "#print(data_t1[:, 0])\n",
    "#print()\n",
    "#print(min(data_t1[:, 7]))\n",
    "#print(max(data_t1[:, 7]))\n",
    "#print()\n",
    "\n",
    "\n",
    "#my_r = my_data[:, 7, 0]\n",
    "\n",
    "#sorted_data = np.array(sorted(data_t1, key=lambda x:x[7]))\n",
    "#print(np.shape(sorted_data))\n",
    "#print(type(sorted_data))\n",
    "#print(sorted_data[:,7])\n",
    "#print(sorted_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "31bc6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumsum_mass = np.cumsum(sorted_data[:, 0])\n",
    "#print(cumsum_mass[3200:3300])\n",
    "#print(len(cumsum_mass))\n",
    "#print(np.sum(data_t1[:, 0]))\n",
    "#print(cumsum_mass[-1])\n",
    "#Mtot = cumsum_mass[-1]\n",
    "#half_mass = 0.5*Mtot\n",
    "#print(f'{half_mass = }')\n",
    "\n",
    "#half_mass_diff = np.abs(cumsum_mass - half_mass)\n",
    "#closest = np.min(half_mass_diff)\n",
    "#print(closest)\n",
    "#position = np.where(half_mass_diff==closest)[0]\n",
    "#print(half_mass_diff[position])\n",
    "#print(cumsum_mass[position])\n",
    "#print(sorted_data[position, 7], position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c7d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6590c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_test = 6.17909780681924\n",
      "difference = 808.6573131521109\n",
      "r_test = 9.268646710228861\n",
      "difference = 110.85027228494118\n",
      "r_test = 9.268646710228861\n",
      "difference = 110.85027228494118\n",
      "\n",
      "9.268646710228861\n"
     ]
    }
   ],
   "source": [
    "#r_halfmass = halfmass_radius_finder(my_data[:, 0, 0], my_data[:, 7, 0])\n",
    "#print()\n",
    "#print(r_halfmass)\n",
    "#print()\n",
    "#r_halfmass2 = halfmass_radius(my_data[:, 0, 5], my_radii)\n",
    "#print()\n",
    "#print(r_halfmass2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82562ace",
   "metadata": {},
   "source": [
    "# Unused functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halfmass_radius_finder(masses, radii):\n",
    "    Mtot = np.sum(masses)\n",
    "    \n",
    "    r_max = np.max(radii)\n",
    "    r_test = 0.5*r_max\n",
    "    r_tests = []\n",
    "    r_tests.append(r_test)\n",
    "    n_part_inside = []\n",
    "    \n",
    "    masses_inside = masses[radii<=r_test]\n",
    "    Mtot_inside = np.sum(masses_inside)\n",
    "    n_part_inside.append(len(masses_inside))\n",
    "    #print(len(masses_inside))\n",
    "    difference = 0.5*Mtot-Mtot_inside\n",
    "    \n",
    "    if np.abs(difference)<=1e-1:\n",
    "        return r_test\n",
    "    \n",
    "    else:\n",
    "        if difference<0:\n",
    "            r_test = r_test - 0.5*r_test\n",
    "            r_tests.append(r_test)\n",
    "            \n",
    "        elif difference>0:\n",
    "            r_test = r_test + 0.5*r_test\n",
    "            r_tests.append(r_test)\n",
    "            \n",
    "        \n",
    "        masses_inside = masses[radii<=r_test]\n",
    "        n_part_inside.append(len(masses_inside))\n",
    "        #print(len(masses_inside))\n",
    "        Mtot_inside = np.sum(masses_inside)\n",
    "        difference = 0.5*Mtot-Mtot_inside\n",
    "        it = 1\n",
    "        while np.abs(difference)>1e-1:\n",
    "            print(f'{r_test = }')\n",
    "            print(f'{difference = }')\n",
    "            if difference<0:\n",
    "                r_test = r_test - 0.5*np.abs(r_test-r_tests[it-1])\n",
    "                \n",
    "                r_tests[it] = r_test\n",
    "                r_tests.append(r_test)\n",
    "                \n",
    "                masses_inside = masses[radii<=r_test]\n",
    "                #print(len(masses_inside))\n",
    "                n_part_inside.append(len(masses_inside))\n",
    "                if len(masses_inside)==n_part_inside[it-1]:\n",
    "                    return r_test\n",
    "                    break\n",
    "                Mtot_inside = np.sum(masses_inside)\n",
    "                difference = 0.5*Mtot-Mtot_inside\n",
    "                it = it+1\n",
    "                \n",
    "                \n",
    "            elif difference>0:\n",
    "                r_test = r_test + 0.5*np.abs(r_test-r_tests[it-1])\n",
    "                \n",
    "                r_tests[it] = r_test\n",
    "                r_tests.append(r_test)\n",
    "                masses_inside = masses[radii<=r_test]\n",
    "                #print(len(masses_inside))\n",
    "                n_part_inside.append(len(masses_inside))\n",
    "                if len(masses_inside)==n_part_inside[it-1]:\n",
    "                    return r_test\n",
    "                    break\n",
    "                Mtot_inside = np.sum(masses_inside)\n",
    "                difference = 0.5*Mtot-Mtot_inside\n",
    "                it = it+1\n",
    "                \n",
    "        return r_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
